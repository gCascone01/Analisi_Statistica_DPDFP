---
title: "SAD Project"
author: "Cascone Giovanni (0522511934), Vitale Ciro (0522501759)"
date: "2023-12-06"
output:
  html_document:
    toc: true
    theme: united
  pdf_document: default
---

# Caricamento Dataset e Preparazione

```{r setup, include=FALSE}
library(readxl)
library(ggplot2)

#---- DEFINIZIONE DEI PATH ----

# pathGitProject_Gio = "C:/Users/user/Desktop/Magistrale/Statistica e Analisi dei Dati/SAD_PROJECT/SAD_Project"
# setwd(pathGitProject_Gio)
# source("Functions.R")

pathGitProject_Ciro = "C:/Users/UTENTE/git/SAD_Project"
setwd(pathGitProject_Ciro)
source("Functions.R")

#---- CARICAMENTO DEI DATASET ----

n_countries = 27

mydata = read_xlsx('./Datasets/European-Country/Complete_Dataset.xlsx', 1)
data = as.matrix(mydata)

mydpm2019 = read_xlsx('./Datasets/European-Country/Complete_Dataset.xlsx', 1)
dpm2019 = as.matrix(mydpm2019)
myvsl2019 = read_xlsx('./Datasets/European-Country/Complete_Dataset.xlsx', 1)
vsl2019 = as.matrix(myvsl2019)

mydata15 = read_xlsx('./Datasets/European-Country/less15.xlsx', 1)
data15 = as.matrix(mydata15)

mydataComp = read_xlsx('./Datasets/European-Country/15-64.xlsx', 1)
dataComp = as.matrix(mydataComp)

mydata64 = read_xlsx('./Datasets/European-Country/64.xlsx', 1)
data64 = as.matrix(mydata64)

#---- PREPARAZIONE DATASET ----

dataset = matrix( as.double(matrix(data[,-1],nrow=n_countries)) , nrow=n_countries)

ds_dpm2019 = matrix( as.double(matrix(dpm2019[,-1],nrow=n_countries)) , nrow=n_countries)
ds_vsl2019 = matrix( as.double(matrix(vsl2019[,-1],nrow=n_countries)) , nrow=n_countries)

dataset15 = matrix( as.double(matrix(data15[,-1],nrow=n_countries)) , nrow=n_countries)

datasetComp = matrix( as.double(matrix(dataComp[,-1],nrow=n_countries)) , nrow=n_countries)

dataset64 = matrix( as.double(matrix(data64[,-1],nrow=n_countries)) , nrow=n_countries)

ds_dpm2019 = ds_dpm2019[,-c(1:48,50)]
ds_vsl2019 = ds_vsl2019[,-c(1:49)]

dataset=dataset[,-c(1:10,49:50)]

dataset15=dataset15[,-c(1:10,49:50)]

datasetComp=datasetComp[,-c(1:10,49:50)]

dataset64=dataset64[,-c(1:10,49:50)]

# Definizione labels Nazioni (righe)

countries = c("Austria", "Belgio", "Bulgaria", "Cipro", "Croazia", "Danimarca", "Estonia", "Finlandia", "Francia", "Germania", "Grecia", "Ungheria", "Irlanda", "Italia", "Lettonia", "Lituania", "Lussemburgo", "Malta", "Paesi Bassi", "Polonia", "Portogallo", "Rep. Ceca", "Romania", "Slovacchia", "Slovenia", "Spagna", "Svezia")
rownames(dataset) = countries
rownames(dataset15) = countries
rownames(datasetComp) = countries
rownames(dataset64) = countries
rownames(ds_dpm2019) = countries
rownames(ds_vsl2019) = countries

# Suddivisione dei valori per DPM (D) e VSL (V) in dataset separati

D_Index = seq(1,48, by=2) 
V_Index = seq(2,49, by=2)

D_dataset = dataset[, D_Index]
V_dataset = dataset[, V_Index]

D_dataset15 = dataset15[, D_Index]
V_dataset15 = dataset15[, V_Index]

D_datasetComp = datasetComp[, D_Index]
V_datasetComp = datasetComp[, V_Index]

D_dataset64 = dataset64[, D_Index]
V_dataset64 = dataset64[, V_Index]

years = seq(1995,2018)
colnames(D_dataset) = years
colnames(V_dataset) = years

colnames(D_dataset15) = years
colnames(V_dataset15) = years

colnames(D_datasetComp) = years
colnames(V_datasetComp) = years

colnames(D_dataset64) = years
colnames(V_dataset64) = years
```

# Analisi Esplorativa del Dataset

## Indici di Centralità

### Indici di Centralità per DPM

```{r indici di centralità, echo=FALSE}
#---- CALCOLO INDICI CENTRALITÀ ----

D_min = min(D_dataset)
D_min15 = min(D_dataset15)
D_minComp = min(D_datasetComp)
D_min64 = min(D_dataset64)

V_min = min(V_dataset)
V_min15 = min(V_dataset15)
V_minComp = min(V_datasetComp)
V_min64 = min(V_dataset64)

D_max = max(D_dataset)
D_max15 = max(D_dataset15)
D_maxComp = max(D_datasetComp)
D_max64 = max(D_dataset64)

V_max = max(V_dataset)
V_max15 = max(V_dataset15)
V_maxComp = max(V_datasetComp)
V_max64 = max(V_dataset64)

D_mean = mean(D_dataset)
D_mean15 = mean(D_dataset15)
D_meanComp = mean(D_datasetComp)
D_mean64 = mean(D_dataset64)

V_mean = mean(V_dataset)
V_mean15 = mean(V_dataset15)
V_meanComp = mean(V_datasetComp)
V_mean64 = mean(V_dataset64)

D_median = median(D_dataset)
D_median15 = median(D_dataset15)
D_medianComp = median(D_datasetComp)
D_median64 = median(D_dataset64)

V_median = median(V_dataset)
V_median15 = median(V_dataset15)
V_medianComp = median(V_datasetComp)
V_median64 = median(V_dataset64)

D_indiciCentr = rbind(c(D_min,D_max,D_mean,D_median),c(D_min15,D_max15,D_mean15,D_median15),c(D_minComp,D_maxComp,D_meanComp,D_medianComp),c(D_min64,D_max64,D_mean64,D_median64))
colnames(D_indiciCentr) = c("MIN", "MAX", "MEDIA", "MEDIANA")
rownames(D_indiciCentr) = c("ALL","LESS 15","COMP 15 - 64","GREATER 64")

V_indiciCentr = rbind(c(V_min,V_max,V_mean,V_median),c(V_min15,V_max15,V_mean15,V_median15),c(V_minComp,V_maxComp,V_meanComp,V_medianComp),c(V_min64,V_max64,V_mean64,V_median64))
colnames(V_indiciCentr) = c("MIN", "MAX", "MEDIA", "MEDIANA")
rownames(V_indiciCentr) = c("ALL","LESS 15","COMP 15 - 64","GREATER 64")
```


```{r view DPM indici di centralità, echo=FALSE}
D_indiciCentr
```

### Indici di Centralità per VSL

```{r view VSL indici di centralità, echo=FALSE}
V_indiciCentr
```

## Indici di Dispersione

```{r indici di dispersione, echo=FALSE}
#---- CALCOLO INDICI DISPERSIONE ----

D_cdv = cv(D_dataset)
D_cdv
D_cdv15 = cv(D_dataset15)
D_cdv15
D_cdvComp = cv(D_datasetComp)
D_cdvComp
D_cdv64 = cv(D_dataset64)
D_cdv64

V_cdv = cv(V_dataset)
V_cdv

D_diffInterq = unname(quantile(sort(D_dataset), probs = 0.75)) - unname(quantile(sort(D_dataset), probs = 0.25))
D_diffInterq15 = unname(quantile(sort(D_dataset15), probs = 0.75)) - unname(quantile(sort(D_dataset15), probs = 0.25))
D_diffInterqComp = unname(quantile(sort(D_datasetComp), probs = 0.75)) - unname(quantile(sort(D_datasetComp), probs = 0.25))
D_diffInterq64 = unname(quantile(sort(D_dataset64), probs = 0.75)) - unname(quantile(sort(D_dataset64), probs = 0.25))

V_diffInterq = unname(quantile(sort(V_dataset), probs = 0.75)) - unname(quantile(sort(V_dataset), probs = 0.25))
V_diffInterq15 = unname(quantile(sort(V_dataset15), probs = 0.75)) - unname(quantile(sort(V_dataset15), probs = 0.25))
V_diffInterqComp = unname(quantile(sort(V_datasetComp), probs = 0.75)) - unname(quantile(sort(V_datasetComp), probs = 0.25))
V_diffInterq64 = unname(quantile(sort(V_dataset64), probs = 0.75)) - unname(quantile(sort(V_dataset64), probs = 0.25))

D_var = var(as.vector(D_dataset))
D_var15 = var(as.vector(D_dataset15))
D_varComp = var(as.vector(D_datasetComp))
D_var64 = var(as.vector(D_dataset64))

V_var = var(as.vector(V_dataset))
V_var15 = var(as.vector(V_dataset15))
V_varComp = var(as.vector(V_datasetComp))
V_var64 = var(as.vector(V_dataset64))

D_sd = sd(D_dataset)
D_sd15 = sd(D_dataset15)
D_sdComp = sd(D_datasetComp)
D_sd64 = sd(D_dataset64)

V_sd = sd(V_dataset)
V_sd15 = sd(V_dataset15)
V_sdComp = sd(V_datasetComp)
V_sd64 = sd(V_dataset64)

D_indiciDisp = rbind(c(D_cdv,D_diffInterq,D_var,D_sd),c(D_cdv15,D_diffInterq15,D_var15,D_sd15),c(D_cdvComp,D_diffInterqComp,D_varComp,D_sdComp),c(D_cdv64,D_diffInterq64,D_var64,D_sd64))
colnames(D_indiciDisp) = c("CdV", "DIFF. INTERQ.", "VARIANZA", "DEVIAZ. STD")
rownames(D_indiciDisp) = c("ALL","LESS 15","COMP 15 - 64","GREATER 64")

V_indiciDisp = rbind(c(V_cdv,V_diffInterq,V_var,V_sd))
colnames(V_indiciDisp) = c("CdV", "DIFF. INTERQ.", "VARIANZA", "DEVIAZ. STD")
rownames(V_indiciDisp) = c("ALL")
```

### Indici di Dispersione per DPM

```{r view DPM indici di dispersione, echo=FALSE}
D_indiciDisp
```

### Indici di Dispersione per VSL

```{r view VSL indici di dispersione, echo=FALSE}
V_indiciDisp
```

## Quantili

```{r quantili, echo=FALSE}
par(mfrow=c(2, 3))

f_quantili(1,D_dataset, "DPM - ALL")
f_quantili(6,D_dataset, "DPM - ALL")
f_quantili(11,D_dataset, "DPM - ALL")
f_quantili(16,D_dataset, "DPM - ALL")
f_quantili(21,D_dataset, "DPM - ALL")
par(mfrow=c(1, 1))
par(mfrow=c(2, 3))

f_quantili(1,D_dataset15, "DPM - LESS 15")
f_quantili(6,D_dataset15, "DPM - LESS 15")
f_quantili(11,D_dataset15, "DPM - LESS 15")
f_quantili(16,D_dataset15, "DPM - LESS 15")
f_quantili(21,D_dataset15, "DPM - LESS 15")

par(mfrow=c(1, 1))
par(mfrow=c(2, 3))

f_quantili(1,D_datasetComp, "DPM - COMP 15 - 64")
f_quantili(6,D_datasetComp, "DPM - COMP 15 - 64")
f_quantili(11,D_datasetComp, "DPM - COMP 15 - 64")
f_quantili(16,D_datasetComp, "DPM - COMP 15 - 64")
f_quantili(21,D_datasetComp, "DPM - COMP 15 - 64")

par(mfrow=c(1, 1))
par(mfrow=c(2, 3))

f_quantili(1,D_dataset64, "DPM - GREATER 64")
f_quantili(6,D_dataset64, "DPM - GREATER 64")
f_quantili(11,D_dataset64, "DPM - GREATER 64")
f_quantili(16,D_dataset64, "DPM - GREATER 64")
f_quantili(21,D_dataset64, "DPM - GREATER 64")

par(mfrow=c(1, 1))
par(mfrow=c(2, 3))

f_quantili(1,V_dataset, "VSL - ALL")
f_quantili(6,V_dataset, "VSL - ALL")
f_quantili(11,V_dataset, "VSL - ALL")
f_quantili(16,V_dataset, "VSL - ALL")
f_quantili(21,V_dataset, "VSL - ALL")

par(mfrow=c(1, 1))
par(mfrow=c(2, 3))

par(mfrow=c(1, 1))
```

# Statistica Descrittiva Univariata

## Funzione di Distribuzione Empirica

```{r FdDC, echo=FALSE}
#---- FdDC - Funzione di Distribuzione Empirica Continua ----

par(mfrow=c(2, 2))

for(country in countries){
  f_FdDC(country)
}

par(mfrow=c(1, 1))

```

## Serie Temporali

```{r serie temporali, echo=FALSE}
f_timeSeries(D_dataset, "DPM ALL")
f_timeSeries(V_dataset, "VSL ALL")

f_timeSeries(D_dataset15, "DPM LESS 15")
f_timeSeries(D_datasetComp, "DPM COMP 15 - 64")
f_timeSeries(D_dataset64, "DPM GREATER 64")
```

## Grafico a Barre Sovrapposte

```{r grafico a barre sovrapposte DPM, echo=FALSE}


#---- GRAFICO A BARRE SOVRAPPOSTE ----
for(country in countries){
  print(f_barre_sovrapp_per_eta(country,D_dataset15,D_datasetComp,D_dataset64,"DPM"))
}

```

# Statistica Descrittiva Bivariata

## Regressione

```{r grafici di regressione, echo=FALSE}

#---- GRAFICI DI REGRESSIONE ----


par(mfrow=c(1, 2))

reg_non_lin_best_model <- character()
reg_non_lin_best_r_squared <- numeric()
reg_non_lin_best_resid <- numeric()

summary_models <- data.frame(best_model=character(), c_cor=numeric(), lin = numeric(), quad = numeric(), exp = numeric(), semilog = numeric(), log = numeric(), stringsAsFactors = FALSE)

for(country in countries) {
  results <- best_model_function(V_dataset[country, ], D_dataset[country, ], country)
  
  reg_non_lin_best_model <- c(reg_non_lin_best_model, results$model)
  reg_non_lin_best_r_squared <- c(reg_non_lin_best_r_squared, results$r_squared)
  reg_non_lin_best_resid <- c(reg_non_lin_best_resid, results$resid)
  
  summary_models <- rbind(summary_models, results$summary)
}

row.names(summary_models) <- countries

par(mfrow=c(1, 1))

res_reg_non_lin <- data.frame(
  model = reg_non_lin_best_model,
  r_squared = reg_non_lin_best_r_squared, 
  resid = reg_non_lin_best_resid
)

summary_models
```

# Analisi dei Cluster

```{r clustering setup VSL, echo=FALSE}

V_distance <- dist(V_dataset, method="euclidean")

# Matrice di non omog. totale
V_WI <- cov(V_dataset)

# Matrice statistica di non omog. totale
V_n <- length(V_dataset)

V_HI <- (V_n-1)*V_WI

# Traccia di HI
V_trHI <- sum(diag(V_HI))

```

## Metodi gerarchici DPM

```{r clustering setup DPM, echo=FALSE}

# Matrice distanze

D_distance <- dist(D_dataset, method="euclidean")

# Matrice di non omog. totale

D_WI <- cov(D_dataset)

# Matrice statistica di non omog. totale

D_n <- length(D_dataset)

D_HI <- (D_n-1)*D_WI

# Traccia di HI

D_trHI <- sum(diag(D_HI))

```

### Metodo del legame singolo

```{r clustering metodi gerarchici - legame singolo DPM, echo=FALSE}

#---- METODI GERARCHICI ----

#---- METODO DEL LEGAME SINGOLO ----

num_clusters <- 2:10
hls <- hclust(D_distance, method="single")

# Dendogramma
  
plot(hls, hang=-1, xlab=paste("DPM - Metodo gerarchico agglomerativo"), sub=paste("del legame singolo"))
axis(side=4, at=round(c(0, hls$height), 2))

# Screeplot

plot(c(0, hls$height), seq(n_countries,1), type="b", main="Screeplot", xlab="Distanza di aggregazione", ylab="Numero di cluster", col="red")

#

trH_within_values <- numeric(length(num_clusters))
trH_between_values <- numeric(length(num_clusters))

for(i in num_clusters){
  n_clust <- i
  D_trH_average_results <- hierarchClustering(hls, n_clust, D_dataset, "del legame singolo", D_trHI, "DPM")
  
  trH_within_values[i-1] <- D_trH_average_results[["trH_within"]]
  trH_between_values[i-1] <- D_trH_average_results[["trH_between"]]
}

plot(num_clusters, trH_within_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_within)", main="Analisi del Numero Ottimale di Cluster")
plot(num_clusters, trH_between_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_between)", main="Analisi del Numero Ottimale di Cluster")

```

### Metodo del legame completo

```{r clustering metodi gerarchici - legame completo DPM, echo=FALSE}

#---- METODI GERARCHICI ----

#---- METODO DEL LEGAME COMPLETO ----
num_clusters <- 2:10
hls <- hclust(D_distance, method="complete")

# Dendogramma
  
plot(hls, hang=-1, xlab=paste("DPM - Metodo gerarchico agglomerativo"), sub=paste("del legame completo"))
axis(side=4, at=round(c(0, hls$height), 2))

# Screeplot

plot(c(0, hls$height), seq(n_countries,1), type="b", main="Screeplot", xlab="Distanza di aggregazione", ylab="Numero di cluster", col="red")

#

trH_within_values <- numeric(length(num_clusters))
trH_between_values <- numeric(length(num_clusters))

for(i in num_clusters){
  n_clust <- i
  D_trH_average_results <- hierarchClustering(hls, n_clust, D_dataset, "del legame completo", D_trHI, "DPM")
  
  trH_within_values[i-1] <- D_trH_average_results[["trH_within"]]
  trH_between_values[i-1] <- D_trH_average_results[["trH_between"]]
}

plot(num_clusters, trH_within_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_within)", main="Analisi del Numero Ottimale di Cluster")
plot(num_clusters, trH_between_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_between)", main="Analisi del Numero Ottimale di Cluster")


#



```

### Metodo del legame medio

```{r clustering metodi gerarchici - legame medio DPM, echo=FALSE}

#---- METODI GERARCHICI ----

#---- METODO DEL LEGAME MEDIO ----
num_clusters <- 2:10
hls <- hclust(D_distance, method="average")

# Dendogramma
  
plot(hls, hang=-1, xlab=paste("DPM - Metodo gerarchico agglomerativo"), sub=paste("del legame medio"))
axis(side=4, at=round(c(0, hls$height), 2))

# Screeplot

plot(c(0, hls$height), seq(n_countries,1), type="b", main="Screeplot", xlab="Distanza di aggregazione", ylab="Numero di cluster", col="red")

#

trH_within_values <- numeric(length(num_clusters))
trH_between_values <- numeric(length(num_clusters))

for(i in num_clusters){
  n_clust <- i
  D_trH_average_results <- hierarchClustering(hls, n_clust, D_dataset, "del legame medio", D_trHI, "DPM")
  
  trH_within_values[i-1] <- D_trH_average_results[["trH_within"]]
  trH_between_values[i-1] <- D_trH_average_results[["trH_between"]]
}

plot(num_clusters, trH_within_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_within)", main="Analisi del Numero Ottimale di Cluster")
plot(num_clusters, trH_between_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_between)", main="Analisi del Numero Ottimale di Cluster")


# 



```

### Metodo del centroide

```{r clustering metodi gerarchici - centroide DPM, echo=FALSE}

#---- METODI GERARCHICI ----

#---- METODO DEL CENTROIDE ----
num_clusters <- 2:10
D_distance2 <- D_distance^2
hls <- hclust(D_distance2, method="centroid")

# Dendogramma
  
plot(hls, hang=-1, xlab=paste("DPM - Metodo gerarchico agglomerativo"), sub=paste("del centroide"))
axis(side=4, at=round(c(0, hls$height), 2))

# Screeplot

plot(c(0, hls$height), seq(n_countries,1), type="b", main="Screeplot", xlab="Distanza di aggregazione", ylab="Numero di cluster", col="red")

#

trH_within_values <- numeric(length(num_clusters))
trH_between_values <- numeric(length(num_clusters))

for(i in num_clusters){
  n_clust <- i
  D_trH_average_results <- hierarchClustering(hls, n_clust, D_dataset, "del centroide", D_trHI, "DPM")
  
  trH_within_values[i-1] <- D_trH_average_results[["trH_within"]]
  trH_between_values[i-1] <- D_trH_average_results[["trH_between"]]
}

plot(num_clusters, trH_within_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_within)", main="Analisi del Numero Ottimale di Cluster")
plot(num_clusters, trH_between_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_between)", main="Analisi del Numero Ottimale di Cluster")


#


```


### Metodo della mediana

```{r clustering metodi gerarchici - mediana DPM, echo=FALSE}

#---- METODI GERARCHICI ----

#---- METODO DELLA MEDIANA ----
num_clusters <- 2:10
D_distance2 <- D_distance^2
hls <- hclust(D_distance2, method="median")

# Dendogramma

plot(hls, hang=-1, xlab=paste("DPM - Metodo gerarchico agglomerativo"), sub=paste("della mediana"))
axis(side=4, at=round(c(0, hls$height), 2))

# Screeplot

plot(c(0, hls$height), seq(n_countries,1), type="b", main="Screeplot", xlab="Distanza di aggregazione", ylab="Numero di cluster", col="red")

#

trH_within_values <- numeric(length(num_clusters))
trH_between_values <- numeric(length(num_clusters))

for(i in num_clusters){
  n_clust <- i
  D_trH_average_results <- hierarchClustering(hls, n_clust, D_dataset, "della mediana", D_trHI, "DPM")
  
  trH_within_values[i-1] <- D_trH_average_results[["trH_within"]]
  trH_between_values[i-1] <- D_trH_average_results[["trH_between"]]
}

plot(num_clusters, trH_within_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_within)", main="Analisi del Numero Ottimale di Cluster")
plot(num_clusters, trH_between_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_between)", main="Analisi del Numero Ottimale di Cluster")


#


```

## Metodi non gerarchici DPM

### Metodo kmeans

```{r clustering metodi non gerarchici - kmeans DPM, echo=FALSE}

#---- METODI NON GERARCHICI ----

#---- METODO KMEANS ----
n_clust = 4:6
for(i in n_clust){
  D_km <- kMeansClustering(D_dataset, i, 5, 10, "DPM")

  D_trH_km_within <- D_km[["trH_within"]]
  
  D_trH_km_between <- D_km[["trH_between"]]
  
  D_km_clusters <- D_km[["clusters"]]
}

```


## Metodi gerarchici VSL

### Metodo del legame singolo

```{r clustering metodi gerarchici - legame singolo VSL, echo=FALSE}
num_clusters <- 2:8
hls <- hclust(V_distance, method="single")

# Dendogramma
plot(hls, hang=-1, xlab=paste("VSL - Metodo gerarchico agglomerativo"), sub=paste("del legame singolo"))
axis(side=4, at=round(c(0, hls$height), 2))

# Screeplot
plot(c(0, hls$height), seq(n_countries,1), type="b", main="Screeplot", xlab="Distanza di aggregazione", ylab="Numero di cluster", col="red")

trH_within_values <- numeric(length(num_clusters))
trH_between_values <- numeric(length(num_clusters))

for(i in num_clusters){
  n_clust <- i
  V_trH_average_results <- hierarchClustering(hls, n_clust, V_dataset, "del legame singolo", V_trHI, "VSL")
  
  trH_within_values[i-1] <- V_trH_average_results[["trH_within"]]
  trH_between_values[i-1] <- V_trH_average_results[["trH_between"]]
}

plot(num_clusters, trH_within_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_within)", main="Analisi del Numero Ottimale di Cluster")
plot(num_clusters, trH_between_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_between)", main="Analisi del Numero Ottimale di Cluster")
```

### Metodo del legame completo

```{r clustering metodi gerarchici - legame completo VSL, echo=FALSE}
num_clusters <- 2:8
hls <- hclust(V_distance, method="complete")

# Dendogramma
plot(hls, hang=-1, xlab=paste("VSL - Metodo gerarchico agglomerativo"), sub=paste("del legame completo"))
axis(side=4, at=round(c(0, hls$height), 2))

# Screeplot
plot(c(0, hls$height), seq(n_countries,1), type="b", main="Screeplot", xlab="Distanza di aggregazione", ylab="Numero di cluster", col="red")

trH_within_values <- numeric(length(num_clusters))
trH_between_values <- numeric(length(num_clusters))

for(i in num_clusters){
  n_clust <- i
  V_trH_average_results <- hierarchClustering(hls, n_clust, V_dataset, "del legame completo", V_trHI, "VSL")
  
  trH_within_values[i-1] <- V_trH_average_results[["trH_within"]]
  trH_between_values[i-1] <- V_trH_average_results[["trH_between"]]
}

plot(num_clusters, trH_within_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_within)", main="Analisi del Numero Ottimale di Cluster")
plot(num_clusters, trH_between_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_between)", main="Analisi del Numero Ottimale di Cluster")
```

### Metodo del legame medio

```{r clustering metodi gerarchici - legame medio VSL, echo=FALSE}
num_clusters <- 2:8
hls <- hclust(V_distance, method="average")

# Dendogramma
plot(hls, hang=-1, xlab=paste("VSL - Metodo gerarchico agglomerativo"), sub=paste("del legame medio"))
axis(side=4, at=round(c(0, hls$height), 2))

# Screeplot
plot(c(0, hls$height), seq(n_countries,1), type="b", main="Screeplot", xlab="Distanza di aggregazione", ylab="Numero di cluster", col="red")

trH_within_values <- numeric(length(num_clusters))
trH_between_values <- numeric(length(num_clusters))

for(i in num_clusters){
  n_clust <- i
  V_trH_average_results <- hierarchClustering(hls, n_clust, V_dataset, "del legame medio", V_trHI, "VSL")
  
  trH_within_values[i-1] <- V_trH_average_results[["trH_within"]]
  trH_between_values[i-1] <- V_trH_average_results[["trH_between"]]
}

plot(num_clusters, trH_within_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_within)", main="Analisi del Numero Ottimale di Cluster")
plot(num_clusters, trH_between_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_between)", main="Analisi del Numero Ottimale di Cluster")
```

### Metodo del centroide

```{r clustering metodi gerarchici - centroide VSL, echo=FALSE}
num_clusters <- 2:8
V_distance2 <- V_distance^2
hls <- hclust(V_distance2, method="centroid")

# Dendogramma
plot(hls, hang=-1, xlab=paste("VSL - Metodo gerarchico agglomerativo"), sub=paste("del centroide"))
axis(side=4, at=round(c(0, hls$height), 2))

# Screeplot
plot(c(0, hls$height), seq(n_countries,1), type="b", main="Screeplot", xlab="Distanza di aggregazione", ylab="Numero di cluster", col="red")

trH_within_values <- numeric(length(num_clusters))
trH_between_values <- numeric(length(num_clusters))

for(i in num_clusters){
  n_clust <- i
  V_trH_average_results <- hierarchClustering(hls, n_clust, V_dataset, "del centroide", V_trHI, "VSL")
  
  trH_within_values[i-1] <- V_trH_average_results[["trH_within"]]
  trH_between_values[i-1] <- V_trH_average_results[["trH_between"]]
}

plot(num_clusters, trH_within_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_within)", main="Analisi del Numero Ottimale di Cluster")
plot(num_clusters, trH_between_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_between)", main="Analisi del Numero Ottimale di Cluster")

```

### Metodo della mediana

```{r clustering metodi gerarchici - mediana VSL, echo=FALSE}

num_clusters <- 2:8
V_distance2 <- V_distance^2
hls <- hclust(V_distance2, method="median")

# Dendogramma

plot(hls, hang=-1, xlab=paste("VSL - Metodo gerarchico agglomerativo"), sub=paste("della mediana"))
axis(side=4, at=round(c(0, hls$height), 2))

# Screeplot

plot(c(0, hls$height), seq(n_countries,1), type="b", main="Screeplot", xlab="Distanza di aggregazione", ylab="Numero di cluster", col="red")

trH_within_values <- numeric(length(num_clusters))
trH_between_values <- numeric(length(num_clusters))

for(i in num_clusters){
  n_clust <- i
  V_trH_average_results <- hierarchClustering(hls, n_clust, V_dataset, "della mediana", V_trHI, "VSL")
  
  trH_within_values[i-1] <- V_trH_average_results[["trH_within"]]
  trH_between_values[i-1] <- V_trH_average_results[["trH_between"]]
}

plot(num_clusters, trH_within_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_within)", main="Analisi del Numero Ottimale di Cluster")
plot(num_clusters, trH_between_values, type="b", xlab="Numero di Cluster", ylab="Non Omogeneità (trH_between)", main="Analisi del Numero Ottimale di Cluster")

```

## Metodi non gerarchici VSL

### Metodo kmeans

```{r clustering metodi non gerarchici - kmeans VSL, echo=FALSE}
n_clust = 3:5
for(i in n_clust){
  V_km <- kMeansClustering(V_dataset, i, 5, 10, "VSL")

  V_trH_km_within <- V_km[["trH_within"]]
  
  V_trH_km_between <- V_km[["trH_between"]]
  
  V_km_clusters <- V_km[["clusters"]]
}
```


# Inferenza Statistica

## Stima Puntuale

```{r stima puntuale, echo=FALSE}

D_Italia <- as.vector(D_dataset["Italia",])
D_Italia = append(D_Italia,134.877)

n_Italia = length(D_Italia)

mean_Italia <- mean(D_Italia)

sd_Italia <- sd(D_Italia)

a <- numeric(4)

for(i in 1:4){
  a[i] <- qnorm(0.2*i, mean=mean_Italia, sd=sd_Italia)
}

r <- 5

nint <- numeric(r)
nint [1] <- length(which(D_Italia < a [1]) )
for(i in 2:4) {
  nint[i] <- length(which((D_Italia >= a[i-1]) & D_Italia < a[i]))
}
nint[5] <- length ( which ( D_Italia >= a [4]) )

chi2 <- sum ((( nint - n_Italia* 0.2) / sqrt ( n_Italia* 0.2) ) ^2)

# r num di elementi per ogni intervallo di frequenze (per ogni cella)
r <-5
# k num di parametri non noti
k <-2
# r - k -1 gradi di libertà
alpha <- 0.05

qchisq ( alpha /2, df =r -k -1)

qchisq ( 1-alpha /2, df =r -k -1)

# Distribuzione normale!

# --- STIMA PUNTUALE ---

# VALORE STIMATO PER IL PARAMETRO µ
stimamu <- mean ( D_Italia )
stimamu

# VALORE STIMATO PER IL PARAMETRO σ^2
stimasigma2 <-( length ( D_Italia ) -1) * var ( D_Italia )/ length ( D_Italia )
stimasigma2
```

## Intervalli di Confidenza

```{r intervalli di confidenza, echo=FALSE}

# --- INTERVALLI DI CONFIDENZA ---

alpha = 0.05

# µ con σ^2 NOTA

qnorm = qnorm (1 - alpha / 2)
qnorm

mean(D_Italia) - qnorm * sd_Italia/sqrt(n_Italia)
mean(D_Italia) + qnorm * sd_Italia/sqrt(n_Italia)

# µ con σ^2 NON NOTA

qt = qt (1 - alpha /2, df =n_Italia -1)
qt

mean_Italia - qt * sd_Italia / sqrt(n_Italia)
mean_Italia + qt * sd_Italia / sqrt(n_Italia)

# σ^2 con µ NOTA

# Supponiamo mu = 151 (in quanto la media è 151.x)

mu = 151

q1 = qchisq (alpha/2, df=n_Italia)
q2 = qchisq(1-alpha/2, df=n_Italia)
q1
q2

((n_Italia-1)*var(D_Italia) + n_Italia*(mean_Italia-mu)**2)/q2
((n_Italia-1)*var(D_Italia) + n_Italia*(mean_Italia-mu)**2)/q1

# σ^2 con µ NON NOTA

q1 = qchisq ( alpha / 2, df =n_Italia -1)
q2 = qchisq ( 1-alpha/2, df =n_Italia -1)

(n_Italia-1)*var(D_Italia)/q2
(n_Italia-1)*var(D_Italia)/q1

```

## Confronto tra Popolazioni

```{r confronto tra popolazioni, echo=FALSE}
# --- CONFRONTO TRA DUE POPOLAZIONI (NORMALI) ---

# Verifichiamo che la seconda popolazione sia normale con il test del chiquadro

D_Italia_post_2005 <- as.vector(D_dataset["Italia",-(1:9)])
n_Italia_post_2005 = length(D_Italia_post_2005)

mean_Italia_post_2005 <- mean(D_Italia_post_2005)

sd_Italia_post_2005 <- sd(D_Italia_post_2005)

a <- numeric(4)

for(i in 1:4){
  a[i] <- qnorm(0.2*i, mean=mean_Italia_post_2005, sd=sd_Italia_post_2005)
}

r <- 5

nint <- numeric(r)
nint [1] <- length(which(D_Italia_post_2005 < a [1]) )
for(i in 2:4) {
  nint[i] <- length(which((D_Italia_post_2005 >= a[i-1]) & D_Italia_post_2005 < a[i]))
}
nint[5] <- length ( which ( D_Italia_post_2005 >= a [4]) )

chi2 <- sum ((( nint - n_Italia_post_2005* 0.2) / sqrt ( n_Italia_post_2005* 0.2) ) ^2)
chi2

# r num di elementi per ogni intervallo di frequenze (per ogni cella)
r <-5
# k num di parametri non noti
k <-2
# r - k -1 gradi di libertà
alpha <- 0.05

qchisq ( alpha /2, df =r -k -1)

qchisq ( 1-alpha /2, df =r -k -1)

# chi2 compreso --> ipotesi valida --> popolazione normale. Possiamo procedere col confronto

# --- CONFRONTO ---

# µ1 − µ2 con σ^2(1) e σ^2(2) note

qnorm(1-alpha/2, mean = 0, sd = 1)

n_Italia
n_Italia_post_2005

mean_Italia
mean_Italia_post_2005

sd_Italia

mean_Italia - mean_Italia_post_2005 - qnorm(1-alpha/2, mean = 0, sd = 1) * sqrt(sd_Italia^2/n_Italia + sd_Italia^2/n_Italia_post_2005)
mean_Italia - mean_Italia_post_2005 + qnorm(1-alpha/2, mean = 0, sd = 1) * sqrt(sd_Italia^2/n_Italia + sd_Italia^2/n_Italia_post_2005)

# Intervalli positivi -> indicano che il numero di morti è sicuramente superiore nel primo campione (tutti gli anni)
# con un grado di fiducia del 95%

```

## Verifica delle Ipotesi

```{r verifica delle ipotesi, echo=FALSE}

# --- VERIFICA DELLE IPOTESI ---


mean_Italia_post_2005

D_Italia_pre_2005 <- as.vector(D_dataset["Italia",(1:9)])
mean_Italia_pre_2005 <- mean(D_Italia_pre_2005)
mean_Italia_pre_2005

# Vogliamo verificare che il numero di morti medio dal 2005 in poi sia < 167 con una deviazione standard di 10
# Quindi ponendo H0 : mu >= mu0 e H1 : mu < mu0 , vogliamo verificare che sia verificata l'ipotesi H1.
# Applichiamo quindi il TEST UNILATERALE DESTRO

alpha <- 0.05
mu0 <- 167
sigma <- 10
n <- n_Italia_post_2005
meancamp <- mean_Italia_post_2005

meno_z_a = qnorm ( alpha , mean =0 , sd =1)
meno_z_a

z = ( meancamp - mu0 ) /( sigma / sqrt (n) )
z

z > meno_z_a
# z > meno_z_a ? No, pertanto bisogna rifiutare l'ipotesi H0 e, di conseguenze, accettare l'ipotesi H1.

# Per un'ulteriore sicurezza, verifichiamo anche con il test del p_value.
pvalue <- pnorm ( z , mean =0 , sd =1)
pvalue

pvalue > alpha
# pvalue > alpha ? No, pertanto anche il test del pvalue consiglia di rifiutare l'ipotesi nulla H0, quindi accettare H1.

# In questo modo, abbiamo verificato che la media di morti dal 2005 in poi
# è minore di 168, valore che corrisponde alla media riportata negli anni precedenti al 2005.

```

